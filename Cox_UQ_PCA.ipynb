{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "\n",
    "df=pd.read_csv(\"./rnaseq_FPKM_UQ_all.csv\", low_memory=False,index_col=1)\n",
    "df_tumor=df[df['sample_type']=='Tumor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gene expression values # 1109 by 56716\n",
    "df_tumor_gene=df_tumor.iloc[:,1:56717]\n",
    "df_tumor_gene.index.names=['barcode']\n",
    "\n",
    "# clinical information   # 1209 by 82\n",
    "df_tumor_clinical=df_tumor.iloc[:,56717:]\n",
    "df_tumor_clinical=df_tumor_clinical.set_index('barcode')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply PCA to gene features\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# standardize gene features before applying PCA, make mean 0 and unit variance\n",
    "sc=StandardScaler()\n",
    "X_norm=sc.fit_transform(df_tumor_gene)\n",
    "\n",
    "# apply PCA to gene features\n",
    "pca=PCA()\n",
    "X_pca=pca.fit_transform(X_norm)\n",
    "\n",
    "temp=pca.explained_variance_ratio_.cumsum()\n",
    "\n",
    "plt.plot(temp)\n",
    "plt.xlabel('Number of Principle Components')\n",
    "plt.ylabel('Proportion of Variance Explained')\n",
    "plt.show();\n",
    " \n",
    "# select the first 300 PCs and apply the transformation to data:\n",
    "\n",
    "pca=PCA(n_components=300)\n",
    "X_pca=pca.fit_transform(X_norm)\n",
    "\n",
    "temp=pca.explained_variance_ratio_.cumsum()\n",
    "\n",
    "data_x=X_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# survival outcomes\n",
    "data_y=df_tumor_clinical[[\"vital_status\",\"days_to_last_follow_up\",\"days_to_death\"]]\n",
    "time_to_event=[]\n",
    "status=[]\n",
    "for index, row in data_y.iterrows():\n",
    "    if row['vital_status']=='dead':\n",
    "        time_to_event.append(row['days_to_death'])\n",
    "        status.append(1)\n",
    "    elif row['vital_status']=='alive':\n",
    "        time_to_event.append(row['days_to_last_follow_up'])\n",
    "        status.append(0)\n",
    "    else:\n",
    "        time_to_event.append(None)\n",
    "        status.append(None)\n",
    "\n",
    "data_y=data_y.copy()\n",
    "data_y['status']= pd.Series([x==1 for x in status], index=data_y.index)\n",
    "data_y['time_to_event']= pd.Series(time_to_event, index=data_y.index)\n",
    "data_y = data_y.drop(['days_to_last_follow_up','days_to_death','vital_status'], 1)\n",
    "\n",
    "data_y = data_y.to_records(index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(data_y)\n",
    "df['index_col'] = df.index\n",
    "df_null = df[df.isnull().any(axis=1)]\n",
    "df_null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check columus with na outcomes\n",
    "\n",
    "df=pd.DataFrame(data_y)\n",
    "df['index_col'] = df.index\n",
    "df_null = df[df.isnull().any(axis=1)]\n",
    "df_null\n",
    "\n",
    "data_x=np.delete(data_x,[537,944,1070],axis=0)\n",
    "data_y=np.delete(data_y,[537,944,1070])\n",
    "\n",
    "## Correct the follow uo days less than 0 to 0\n",
    "for idx, item in enumerate(data_y['time_to_event']):\n",
    "    if item < 0:\n",
    "        data_y['time_to_event'][idx] = 0\n",
    "data_y\n",
    "\n",
    "df.groupby('status').count()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cox-PH model with Ridge Penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sksurv.linear_model import CoxPHSurvivalAnalysis\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# tuning parameter alpha over grid search according to c-index\n",
    "\n",
    "coxph = CoxPHSurvivalAnalysis()\n",
    "grid_values={'alpha': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]}\n",
    "\n",
    "grid_c = GridSearchCV(coxph, param_grid = grid_values, scoring = None)\n",
    "grid_c.fit(data_x, data_y) \n",
    "\n",
    "print('Grid best parameter (max c-index): ', grid_c.best_params_)\n",
    "print('Grid best score (c-index): ', grid_c.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Cox-PH model based on 5-fold 10-repeated CV using optimal alpha selected from grid search:\n",
    "\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "\n",
    "rkf = RepeatedKFold(n_splits=5, n_repeats=10, random_state=0) # 5-fold 10-repeated CV\n",
    "\n",
    "c_index_train,c_index_test=[],[]\n",
    "\n",
    "for train_index, test_index in rkf.split(data_x):\n",
    "    x_train, x_test = data_x[train_index], data_x[test_index]\n",
    "    y_train, y_test = data_y[train_index], data_y[test_index]\n",
    "    coxph = CoxPHSurvivalAnalysis(alpha=float(grid_c.best_params_['alpha'])).fit(x_train, y_train)\n",
    "    c_index_train.append(coxph.score(x_train,y_train))\n",
    "    c_index_test.append(coxph.score(x_test,y_test))\n",
    "    \n",
    "print(\"Averaged c-index from 5-fold 10 repeated CV(training): {:.3f}\".format(np.mean(c_index_train)))\n",
    "print(\"Averaged c-index from 5-fold 10 repeated CV(test): {:.3f}\".format(np.mean(c_index_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elastic net Cox-PH model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sksurv.linear_model import CoxnetSurvivalAnalysis\n",
    "\n",
    "alphas=np.arange(0.5,1,0.1)\n",
    "\n",
    "\n",
    "estimator = CoxnetSurvivalAnalysis(n_alphas=5, alphas=alphas, l1_ratio=0.7)\n",
    "estimator.fit(data_x, data_y)\n",
    "\n",
    "estimator.score(data_x, data_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define a function for evaluating the performance of models during grid search using Harrell's concordance index\n",
    "def score_survival_model(model, X, y):\n",
    "    prediction = model.predict(X)\n",
    "    result = concordance_index_censored(y['status'], y['time_to_event'], prediction)\n",
    "    return result[0]\n",
    "\n",
    "param_grid = {'alpha': 2. ** np.arange(-12, 13, 2)}\n",
    "cv = ShuffleSplit(n_splits=200, train_size=0.5, random_state=0)\n",
    "gcv = GridSearchCV(estimator, param_grid, scoring=score_survival_model,\n",
    "                   n_jobs=4, iid=False, refit=False,\n",
    "                   cv=cv)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "gcv = gcv.fit(data_x, data_y)\n",
    "\n",
    "print(gcv.best_score_)\n",
    "print(gcv.best_params_)\n",
    "\n",
    "## Finally, we retrieve all 200 test scores for each parameter setting and visualize their distribution by box plots.\n",
    "def plot_performance(gcv):\n",
    "    n_splits = gcv.cv.n_splits\n",
    "    cv_scores = []\n",
    "    for i, params in enumerate(gcv.cv_results_[\"params\"]):\n",
    "        validation_scores = np.empty(n_splits, dtype=float)\n",
    "        for j in range(n_splits):\n",
    "            validation_scores[j] = gcv.cv_results_[\"split%d_test_score\" % j][i]\n",
    "        name = \"%.5f\" % params[\"alpha\"]\n",
    "        cv_scores.append((name, validation_scores))\n",
    "\n",
    "    sns.boxplot(pd.DataFrame.from_items(cv_scores))\n",
    "    _, xtext = plt.xticks()\n",
    "    for t in xtext:\n",
    "        t.set_rotation(\"vertical\")\n",
    "\n",
    "plot_performance(gcv)\n",
    "\n",
    "plt.savefig('./FTSVM_UQ_all_box.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns; sns.set()\n",
    "ax = sns.heatmap(X_pca)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the PCA-transformed data\n",
    "\n",
    "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "import matplotlib.patches as mpatches\n",
    "import numpy\n",
    "\n",
    "def plot_labelled_scatter(X, y, class_labels):\n",
    "    num_labels = len(class_labels)\n",
    "\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "\n",
    "    marker_array = ['o', '^', '*']\n",
    "    color_array = ['#FFFF00', '#00AAFF', '#000000', '#FF00AA']\n",
    "    cmap_bold = ListedColormap(color_array)\n",
    "    bnorm = BoundaryNorm(numpy.arange(0, num_labels + 1, 1), ncolors=num_labels)\n",
    "    plt.figure()\n",
    "\n",
    "    plt.scatter(X[:, 0], X[:, 1], s=65, c=y, cmap=cmap_bold, norm = bnorm, alpha = 0.40, edgecolor='black', lw = 1)\n",
    "\n",
    "    plt.xlim(x_min, x_max)\n",
    "    plt.ylim(y_min, y_max)\n",
    "\n",
    "    h = []\n",
    "    for c in range(0, num_labels):\n",
    "        h.append(mpatches.Patch(color=color_array[c], label=class_labels[c]))\n",
    "    plt.legend(handles=h)\n",
    "\n",
    "    \n",
    "\n",
    "plot_labelled_scatter(X_pca, y, ['Normal','Tumor'])\n",
    "\n",
    "plt.xlabel('First principle component')\n",
    "plt.ylabel('Second principle component')\n",
    "plt.title('TCGA BRCA data PCA(n_component = 2 )')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing PCA components\n",
    "# Plotting the magnitude of each feature value for the first two principal component\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(8, 4))\n",
    "plt.imshow(pca.components_, interpolation = 'none', cmap = 'plasma')\n",
    "feature_names = list(df_gene.columns.values)\n",
    "\n",
    "plt.gca().set_xticks(np.arange(-.5, len(feature_names)));\n",
    "plt.gca().set_yticks(np.arange(0.5, 2));\n",
    "plt.gca().set_xticklabels(feature_names, rotation=90, ha='left', fontsize=12);\n",
    "plt.gca().set_yticklabels(['First PC', 'Second PC'], va='bottom', fontsize=12);\n",
    "\n",
    "plt.colorbar(orientation='horizontal', ticks=[pca.components_.min(), 0, \n",
    "                                              pca.components_.max()], pad=0.65);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manifod Learning (for high-dim data visualization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multidimensional scaling (MDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.manifold import MDS\n",
    "\n",
    "\n",
    "mds = MDS(n_components = 2)\n",
    "\n",
    "X_mds = mds.fit_transform(X_norm)\n",
    "\n",
    "plot_labelled_scatter(X_mds, y, ['Normal', 'Tumor'])\n",
    "\n",
    "plt.xlabel('First MDS dimension')\n",
    "plt.ylabel('Second MDS dimension')\n",
    "plt.title('TCGA BRCA data MDS (n_components = 2)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne = TSNE(random_state = 0,n_components = 2)\n",
    "\n",
    "X_tsne = tsne.fit_transform(X_norm)\n",
    "\n",
    "plot_labelled_scatter(X_tsne, y, \n",
    "    ['Normal', 'Tumor'])\n",
    "plt.xlabel('First t-SNE feature')\n",
    "plt.ylabel('Second t-SNE feature')\n",
    "plt.title('TCGA BRCA data t-SNE');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tsne.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans \n",
    "\n",
    "kmeans=KMeans(n_clusters=5)\n",
    "kmeans.fit(X_norm)\n",
    "\n",
    "plot_labelled_scatter(X_norm, kmeans.labels_, ['Cluster1', 'Cluster2','Cluster3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agglomerative Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "\n",
    "cls = AgglomerativeClustering(n_clusters = 3)\n",
    "cls_assignment = cls.fit_predict(X_norm)\n",
    "\n",
    "plot_labelled_scatter(X_norm, cls_assignment, \n",
    "        ['Cluster 1', 'Cluster 2', 'Cluster 3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dendrogram (using scipy), based on 10 selected samples\n",
    "\n",
    "from scipy.cluster.hierarchy import ward, dendrogram\n",
    "plt.figure()\n",
    "dendrogram(ward(X_norm))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No need to specify number of clusters ahead\n",
    "# Good for larger dataset, efficient\n",
    "# Allow to identify noise points\n",
    "\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "\n",
    "dbscan = DBSCAN(eps = 2, min_samples = 2)\n",
    "\n",
    "cls = dbscan.fit_predict(X_norm)\n",
    "print(\"Cluster membership values:\\n{}\".format(cls))\n",
    "\n",
    "plot_labelled_scatter(X_norm, cls + 1, \n",
    "        ['Noise', 'Cluster 0', 'Cluster 1', 'Cluster 2'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
